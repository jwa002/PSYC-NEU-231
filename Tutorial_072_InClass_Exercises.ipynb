{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In class exercise...\n",
    "* MI is biased in that small sample sizes lead to inaccurate estimates of PDFs, and that can sometimes lead to negative MI values (which should never happen in theory). \n",
    "* A common, and simple, approach, is to compute MI with shuffled condition labels (like randomization tests that we did many weeks back) and then subtract the shuffled MI from the actual MI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KernelDensity\n",
    "# also define the default font we'll use for figures. \n",
    "fig_font = {'fontname':'Arial', 'size':'20'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First set up two arrays of data...make them correlated to some degree so that there is a reasonably high MI... (can just make them discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=500\n",
    "x = np.round(np.random.rand(N))\n",
    "y = np.round(np.random.rand(N))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then compute the MI between the arrays. Can do two discrete arrays for simplicity, and import the entropy and conditional entropy functions from the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(x):\n",
    "    uniquex = np.unique(x)\n",
    "    Hx = 0\n",
    "    for i in np.arange(len(uniquex)):\n",
    "        px = np.sum(x==uniquex[i])/len(x)\n",
    "\n",
    "        if px!=0:\n",
    "            Hx += (-np.sum( px * np.log2(px) ))\n",
    "        else:\n",
    "            print('px is zero for value:', i)\n",
    "\n",
    "        return Hx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condEntropy(x,y):\n",
    "    Hxy = 0\n",
    "    uniquex = np.unique(x)\n",
    "    uniquey = np.unique(y)\n",
    "    \n",
    "    for i in np.arange(len(uniquey)):\n",
    "        py = np.sum(y==uniquey[i]) / N\n",
    "        \n",
    "        tmp=0\n",
    "        for j in np.arange(len(uniquex)):\n",
    "            px_y = np.sum((x==uniquex[j]) & (y==uniquey[i])) / np.sum(y==uniquey[i])\n",
    "            tmp += (-( px_y * np.log2(px_y) )) \n",
    "            \n",
    "        Hxy += py*tmp\n",
    "        \n",
    "    return Hxy\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first MI is:  -0.4895757499483222\n"
     ]
    }
   ],
   "source": [
    "Hx = entropy(x=x)\n",
    "Hxy = condEntropy(x=x,y=y)\n",
    "first_MI = Hx -Hxy\n",
    "print('first MI is: ', first_MI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now repeat the above operations, but shuffle the data arrays and repeat the analysis many times (~500-1000 times). Plot the distribution of MI values that you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.round(np.random.rand(N))\n",
    "y = np.round(np.random.rand(N))\n",
    "\n",
    "num_randomizations = 500\n",
    "rand_MI = np.zeros(num_randomizations)\n",
    "tmp0 = np.zeros(N)\n",
    "tmp1 = np.zeros(N)\n",
    "\n",
    "# start a loop over randomization iterations\n",
    "for i in np.arange(num_randomizations):\n",
    "    \n",
    "    # write this out explicitly for clarity - randomly assigning numbers from d1 or d2\n",
    "    # i.e. condition doesn't matter. \n",
    "    for j in np.arange(N):   \n",
    "        if np.random.rand(1) < .5:\n",
    "            tmp0[j] = x[j]\n",
    "            tmp1[j] = y[j]\n",
    "        else:\n",
    "            tmp0[j] = y[j]\n",
    "            tmp1[j] = x[j]\n",
    "\n",
    "    # then correlate the two randomized data vectors...compute tvalues\n",
    "    rand_MI[i] = entropy(x=tmp0)-condEntropy(x=tmp0,y=tmp1)\n",
    "\n",
    "plt.hist(rand_MI, color='k', alpha=1, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now subtract the mean of the shuffled MI values from your 'real' MI value...this will help correct for any bias that is introduced by a limited sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected MI: 0.011633819397174339\n",
      "Hmm, apparently not much info is mutual\n"
     ]
    }
   ],
   "source": [
    "mean_shuff_MI = np.mean(rand_MI, axis=0)\n",
    "corrected_MI = first_MI - mean_shuff_MI\n",
    "print('Corrected MI:', corrected_MI)\n",
    "print('Hmm, apparently not much info is mutual')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
